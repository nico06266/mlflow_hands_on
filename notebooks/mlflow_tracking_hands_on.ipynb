{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2e0514d",
   "metadata": {},
   "source": [
    "# AI Clinique #13 : Model Lifecycle Management with mlflow\n",
    "\n",
    "- Date : 29-10-2021\n",
    "- Presentators : A. Massiot and N. Clavel\n",
    "- Dataset : For this hands-on, we will be using the [Power Plant dataset](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant) where the goal is to predict the net hourly electrical energy output (EP) of a plant.\n",
    "- Packages : requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75435a56",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "- 1. Case introduction\n",
    "- 2. Train 1st regression model\n",
    "- 3. Track experiments with MLflow Tracking\n",
    "- 4. Visualize experiments with MLflow tracking UI\n",
    "- 5. Serve model with MLflow Model\n",
    "- 6. Search in experiment\n",
    "- 7. Load model from experiment\n",
    "- 8. Backend & artifact Stores (to go further)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f6c240",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, max_error\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51241dbe",
   "metadata": {},
   "source": [
    "## 1. Case introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b7aa3",
   "metadata": {},
   "source": [
    "#### Load the Power Plant dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8113848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power Plant dataset\n",
    "df = pd.read_csv('../input_data/power_plants.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e47d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf937ea",
   "metadata": {},
   "source": [
    "Features consist of hourly :\n",
    "- Ambient Temperature (AT)\n",
    "- Ambient Pressure (AP)\n",
    "- Relative Humidity (RH)\n",
    "- Exhaust Steam Vacuum (V)\n",
    "\n",
    "...to predict the net hourly electrical energy output (PE) of the plant.  \n",
    "\n",
    "A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum is colected from and has effect on the Steam Turbine, the other three ambient variables effect the GT performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e792c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features & target\n",
    "target = 'PE'\n",
    "features = ['AT', 'V', 'AP', 'RH']\n",
    "\n",
    "# Split data\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cccb836",
   "metadata": {},
   "source": [
    "## 2. Train 1st regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e8b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "max_depth = 6\n",
    "model = RandomForestRegressor(max_depth=max_depth)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "me = max_error(y_test, y_pred)\n",
    "print(f'Test mse = {mse}, Test max error = {me}, Random forest max depth = {max_depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff54ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model as a pickle file\n",
    "model_filename = '../models/29-10-2021-rf-model-v3.pkl'\n",
    "pickle.dump(model, open(model_filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0155d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and test it\n",
    "model = pickle.load(open(model_filename, \"rb\"))\n",
    "\n",
    "# check results on test\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "me = max_error(y_test, y_pred)\n",
    "print(f'Test mse = {mse}, Test max error = {me}, Random forest max depth = {max_depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b10ee",
   "metadata": {},
   "source": [
    "#### 29-10-2021-rf-model-v1.pkl is an artifact :  \n",
    "In common ML term , it is used to describe the output created by the training processfile generated by the training. It can be a model (pickle, joblib format), a model checkpoints, an image..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38460a34",
   "metadata": {},
   "source": [
    "#### Let's say we want to modify the hyperparam and change the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98efc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['V', 'AP']\n",
    "\n",
    "# Split data\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit model\n",
    "max_depth = 7\n",
    "model = RandomForestRegressor(max_depth=max_depth)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "me = max_error(y_test, y_pred)\n",
    "print(f'Test mse = {mse}, Test max error = {me}, Random forest max depth = {max_depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2256fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model as a pickle file v2\n",
    "model_filename = '../models/29-10-2021-rf-model-v5.pkl'\n",
    "pickle.dump(model, open(model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f512080",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21074d5c",
   "metadata": {},
   "source": [
    "#### If another Datascient or ML engineer or DevOps, get the code, he may have no clue about the hyperparameters, metrics obtained, and all information regarding how this model has been trained. Maybe he want to know what was the performance of the model, which were the features used..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4604c1",
   "metadata": {},
   "source": [
    "#### ...It's hard to keep tracks of experiments configurations, params, metrics, models artifacts, features used..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfecbcd",
   "metadata": {},
   "source": [
    "## 3. MLflow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ac419",
   "metadata": {},
   "source": [
    "#### Vocabulary:\n",
    "- **run**: single execution of model training code. Each run can record different informations (model parameters, metrics, tags, artifacts, etc).\n",
    "- **experiment**: the primary unit of organization and access control for MLflow runs; all MLflow runs belong to an experiment. Experiments let you visualize, search for, and compare runs, as well as download run artifacts and metadata for analysis in other tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a065fe6",
   "metadata": {},
   "source": [
    "#### 3.1. Random Forest experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe24287",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'ep_prediction_with_random_forest'\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c781e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb018ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls mlruns/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e887a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls mlruns/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a503b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat mlruns/1/meta.yaml "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d4b577",
   "metadata": {},
   "source": [
    "#### Log metrics & params, model & tag\n",
    "1. Log max_depth as param\n",
    "2. Log Tag\n",
    "3. Log features as param\n",
    "4. Log metrics\n",
    "5. Log features as artifact\n",
    "6. Log model as artifact\n",
    "7. Log model with log_model (MLFlow Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d837bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    features = ['AT', 'V', 'AP']\n",
    "    max_depth = 10\n",
    "    tag = {'artifact': 'without artifacts log'}\n",
    "    \n",
    "    # Split data\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit model\n",
    "    model = RandomForestRegressor(max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    ##--- Log tags\n",
    "    mlflow.set_tags(tag)\n",
    "\n",
    "    ##--- Log params\n",
    "    mlflow.log_param('max_depth', max_depth)\n",
    "    #mlflow.log_param('features', features)\n",
    "    \n",
    "    \n",
    "    ##--- Log artifacts\n",
    "    \n",
    "    #-Log features artifact\n",
    "    features_filename = '../features.txt'\n",
    "    with open(features_filename, 'w') as f:\n",
    "        f.write(str(features))\n",
    "    mlflow.log_artifact(features_filename, artifact_path='features')\n",
    "    \n",
    "    #-Log model with log_model\n",
    "    mlflow.sklearn.log_model(model, 'rf_model')\n",
    "    \n",
    "    #-Log model artifact\n",
    "    #model_filename = '../models/29-10-2021-rf-model.pkl'\n",
    "    #pickle.dump(model, open(model_filename, 'wb'))\n",
    "    #mlflow.log_artifact(model_filename)\n",
    "    \n",
    "    # Get artfact URI\n",
    "    #artifact_uri = mlflow.get_artifact_uri()\n",
    "    #print(f'Artifact uri: {artifact_uri}', '\\n')\n",
    "    #features_artifact_uri = mlflow.get_artifact_uri(artifact_path='features/features.txt')\n",
    "    #print(f'Features artifact uri: {features_artifact_uri}', '\\n')\n",
    "    #model_artifact_uri = mlflow.get_artifact_uri(artifact_path='29-10-2021-rf-model-v4.pkl')\n",
    "    #print(f'Model artifact uri: {model_artifact_uri}', '\\n')\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    me = max_error(y_test, y_pred)\n",
    "\n",
    "    ##--- Log metrics\n",
    "    mlflow.log_metrics({'mse': mse, 'me': me}) # or mlflow.log_metric('mse', mse) & mlflow.log_metric('me', me)\n",
    "    print(f'Test mse = {mse}, Test max error  = {me}, Random forest max depth = {max_depth}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee4b288",
   "metadata": {},
   "source": [
    "#### 3.2. Lightgbm experimentation\n",
    "1. Create a new experiment\n",
    "2. Log tag, hyperparams as params, features and model as artifacts with mlflow.lightgbm.log_model (MLFlow model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'ep_prediction_with_lightgbm'\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat  mlruns/2/meta.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef0023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    \n",
    "    features = ['AT', 'V', 'AP', 'RH']\n",
    "    early_topping_rounds = 10\n",
    "    parameters = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'num_leaves': 40,\n",
    "        'learning_rate': 0.05,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    \n",
    "    # Split data\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    \n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    # Fit model\n",
    "    model = lgb.train(parameters,\n",
    "                      train_data,\n",
    "                      valid_sets=val_data,\n",
    "                      early_stopping_rounds=early_topping_rounds)\n",
    "\n",
    "    ##--- Log params : model hyperparameters & features\n",
    "    mlflow.log_params(parameters)\n",
    "    mlflow.log_param('early_topping_rounds', early_topping_rounds)\n",
    "    mlflow.log_param('features', features)\n",
    "    mlflow.lightgbm.log_model(model, 'lgbm_model')\n",
    "    \n",
    "    ##- Get model artifact URI\n",
    "    model_artifact_uri = mlflow.get_artifact_uri(artifact_path='lgbm_model')\n",
    "    print(f'Model artifact uri: {model_artifact_uri}', '\\n')\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    me = max_error(y_test, y_pred)\n",
    "\n",
    "    ##--- Log metrics\n",
    "    mlflow.log_metrics({'mse': mse, 'me': me})\n",
    "    print(f'Test mse = {mse}, Test max error  = {me}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a9059b",
   "metadata": {},
   "source": [
    "#### 3.3. Autolog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b8520",
   "metadata": {},
   "source": [
    "- Automatic logging allows you to log metrics, parameters, and models without the need for explicit log statements\n",
    "- Be careful : autolog does not log test metrics, so you need to log them with log_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c599f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'ep_prediction_with_lightgbm_autolog'\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    features = [\"AT\", \"V\", \"AP\", \"RH\"]\n",
    "    max_depth = 6\n",
    "    \n",
    "    mlflow.autolog()\n",
    "\n",
    "    # Split data\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit model\n",
    "    model = RandomForestRegressor(max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    me = max_error(y_test, y_pred)\n",
    "\n",
    "    ##--- mlflow: log metrics\n",
    "    mlflow.log_metrics({'test_mse': mse, 'test_me': me})\n",
    "    print(f'Test mse = {mse}, Test max error  = {me}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa633d08",
   "metadata": {},
   "source": [
    "#### 3.4. Conclusion :\n",
    "MLflow Tracking enable to track experimentations configurations.\n",
    "- Log parameters (hyperparameters, features, and others...) : log_param() or log_params()\n",
    "- Log metrics : log_metric() or log_metrics()\n",
    "- Log artifacts (models, and any files) : log_artifact() or log_artifacts()\n",
    "- Set tags : set_tag() or set_tags()\n",
    "- Log model : abstraction to load any kind of model library (sklearn, lightgbm, tensorflow, pytorch...) : mlflow.library.log_model()\n",
    "- Autolog() : log everything except metrics performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc0241",
   "metadata": {},
   "source": [
    "## 4. Serve predictions with MLflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c40b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in shell\n",
    "#!mlflow models serve -m file:///C:/Users/nicolas.clavel/Documents/projets/Engie/mlflow_hands_on/notebooks/mlruns/2/27ead034ce7a4a02891697a226e910dc/artifacts/lgbm_model -p 1234 --no-conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6067600",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST -H \"Content-Type:application/json; format=pandas-split\" --data \"{\\\"columns\\\":[\\\"AT\\\", \\\"V\\\", \\\"AP\\\", \\\"RH\\\"],\\\"data\\\":[[12.8, 0.029, 0.48, 0.98]]}\" http://127.0.0.1:1234/invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d1d01b",
   "metadata": {},
   "source": [
    "## 5. Visualize experiments with MLflow tracking UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4143c2",
   "metadata": {},
   "source": [
    "To run the [MLflow Tracking UI](https://www.mlflow.org/docs/latest/tracking.html#tracking-ui), you can run the command ```mlflow ui``` (needs to be executed from the *notebooks* folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7871e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run in command line\n",
    "#!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae529c0",
   "metadata": {},
   "source": [
    "## 6. Search  in experiments\n",
    "- [In the UI directly](https://www.mlflow.org/docs/latest/search-syntax.html#search)\n",
    "- [Programmatically with search_runs](https://www.mlflow.org/docs/latest/search-syntax.html#programmatically-searching-runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0bc0e5",
   "metadata": {},
   "source": [
    "- Get the id of the experiment where we want to search runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'ep_prediction_with_random_forest'\n",
    "mlflow.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25109d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954362f",
   "metadata": {},
   "source": [
    "- Get all runs for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03febb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.search_runs(experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730b48a",
   "metadata": {},
   "source": [
    "- Filter runs by max_depth and mse and order them by mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.search_runs(\n",
    "    experiment_id,\n",
    "    filter_string=f\"metrics.me <= 30\",\n",
    "    order_by=['metrics.me asc']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e81dc25",
   "metadata": {},
   "source": [
    "## 7. Load model from experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77e039",
   "metadata": {},
   "source": [
    "- [More informations on other format of model_uri](https://www.mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.load_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c217c3a",
   "metadata": {},
   "source": [
    "#### 7.1. With the results of search_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = '2'\n",
    "run = mlflow.search_runs(\n",
    "    experiment_id,\n",
    "    order_by=['metrics.mse asc']\n",
    ").iloc[0]\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.artifact_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.lightgbm.load_model(model_uri=f'{run.artifact_uri}/lgbm_model')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faadf397",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(df[:5][['AT', 'V', 'AP', 'RH']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3918ec2",
   "metadata": {},
   "source": [
    "#### 7.2. With the run id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5eba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls mlruns/1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495dd4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls mlruns/1/f4d1ec170de24fe69e2d2d4774e956e7/artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da82580",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = '8bb8efe5f46e45b3920ec0f83f33cf58'\n",
    "model_uri = f'runs:/{run_id}/rf_model_v3'\n",
    "\n",
    "model = mlflow.sklearn.load_model(model_uri=model_uri)\n",
    "model\n",
    "\n",
    "model.predict(df[:5][['AT', 'V', 'AP', 'RH']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafad62",
   "metadata": {},
   "source": [
    "## 8. Backend & artifact Stores (to go further)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb520d80",
   "metadata": {},
   "source": [
    "#### Where mlflow saves the data :\n",
    "- in local filesystem : mlruns/\n",
    "- in backend & artifact stores (local or remote)\n",
    "\n",
    "#### Some vocabulary:\n",
    "- **Backend store**: for MLflow entities (parameters, metrics, tags, metadata, etc) ~ SQL, SQLite, Postgres\n",
    "- **Artefact store**: for artifacts (files, models, images, etc)\n",
    "- For more information, [check the official documentation](https://www.mlflow.org/docs/latest/tracking.html#where-runs-are-recorded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882f490",
   "metadata": {},
   "source": [
    "#### 8.1. Local file system mlruns if no prior config\n",
    "- When no prior configuration is set, MLflow creates an *mlruns* folder where the data will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f728bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ece552",
   "metadata": {},
   "source": [
    "- MLflow created a new folder *mlruns* where it will store the different run informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a656ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!tree mlruns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7778ea2",
   "metadata": {},
   "source": [
    "#### 8.2. Backend (sqlite) & Artifact stores locally (to go further)\n",
    "\n",
    "- Set the **Backend store** to an sqlite database located in */tmp/mlruns.db* and the **Artefact store**  to a folder located in */tmp/mlruns*. For more informations on the different possibilities available (S3, blobstorage, etc) check [the official documentation](https://www.mlflow.org/docs/latest/tracking.html#where-runs-are-recorded).\n",
    "- To run the MLflow server, you needd to execute the following command in your terminal\n",
    "```mlflow server --backend-store-uri sqlite:////tmp/mlruns.db --default-artifact-root /tmp/mlruns```\n",
    "- Set the tracking uri in the notebook ```mlflow.set_tracking_uri('http://127.0.0.1:5000')```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d32c7e",
   "metadata": {},
   "source": [
    "#### 8.3. Backend & Artefact stores remotely (to go further)\n",
    "- Documentation : https://www.mlflow.org/docs/latest/tracking.html#where-runs-are-recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3a363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
